## Reading list on Stochastic Gradient Descent

---

**Author**: billdthompson@berkeley.edu

#### **Convergence:**

- **Convergence diagnostics for stochastic gradient descent with constant step size** (2017) Chee & Toulis [[pdf]](https://arxiv.org/pdf/1710.06382) [[web]](https://arxiv.org/abs/1710.06382)

- **Gradient Descent Learns Linear Dynamical Systems** (2016) Moritz Hardt, Tengyu Ma, Benjamin Recht [[pdf]](https://arxiv.org/pdf/1609.05191.pdf)

- **Stochastic Gradient Descent for Non-smooth Optimization: Convergence Results and Optimal Averaging Schemes** (2012) SHamir & Zhang [[pdf]](https://arxiv.org/abs/1212.1824) 

- **A Lyapunov Analysis of Momentum Methods in Optimization** (2016) Recht [[pdf]](https://arxiv.org/abs/1611.02635)  [[lecture notes]](http://pages.cs.wisc.edu/~brecht/cs726docs/HeavyBallLinear.pdf) 

- **signSGD: compressed optimisation for non-convex problems** (2018) Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, Anima Anandkumar [[pdf]](https://arxiv.org/abs/1802.04434) 

#### **Learning Rates:**

- **The Marginal Value of Adaptive Gradient Methods in Machine Learning** (2017) Ashia C. Wilson, Rebecca Roelofs, Mitchell Stern, Nathan Srebro, Benjamin Recht [[pdf]](https://arxiv.org/abs/1705.08292) 

- **Online Learning Rate Adaptation with Hypergradient Descent** (2017) Atilim Gunes Baydin, Robert Cornish, David Martinez Rubio, Mark Schmidt, Frank Wood [[pdf]](https://arxiv.org/abs/1703.04782) 

- **Learning Gradient Descent: Better Generalization and Longer Horizons** (2017) Kaifeng Lv, Shunhua Jiang, Jian Li [[pdf]](https://arxiv.org/abs/1703.03633)

- **Gradient descent revisited via an adaptive online learning rate** (2018) Mathieu Ravaut, Satya Gorti [[pdf]](https://arxiv.org/abs/1801.09136)

- **Don't Decay the Learning Rate, Increase the Batch Size** (2018) Samuel L. Smith, Pieter-Jan Kindermans, Quoc V. Le [[pdf]](https://arxiv.org/abs/1711.00489)

- **Training Deep Networks without Learning Rates Through Coin Betting** (2017) Francesco Orabona, Tatiana Tommasi [[pdf]](https://arxiv.org/abs/1705.07795)

#### **Weight Decay:**

- **A Simple Weight Decay Can Improve Generalization** (1992) Krogh & Hertz [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.1947&rep=rep1&type=pdf) 

- **Fixing Weight Decay Regularization in Adam** (2017) Ilya Loshchilov, Frank Hutter [[pdf]](https://arxiv.org/abs/1711.05101) 

#### **Bayesian Intepretations:**

- **Early Stopping is Nonparametric Variational Inference** (2015) Dougal Maclaurin, David Duvenaud, Ryan P. Adams [[pdf]](https://arxiv.org/abs/1504.01344)

- **Stochastic Gradient Descent as Approximate Bayesian Inference** (2016) Stephan Mandt, Matthew D. Hoffman, David M. Blei [[pdf]](https://arxiv.org/abs/1704.04289)

- **Recasting Gradient-Based Meta-Learning as Hierarchical Bayes** (2018) Erin Grant, Chelsea Finn, Sergey Levine, Trevor Darrell, Thomas Griffiths[[pdf]](https://arxiv.org/abs/1801.08930)

- **A Bayesian Perspective on Generalization and Stochastic Gradient Descent** (2017) Samuel L. Smith and Quoc V. Le [[pdf]](http://bayesiandeeplearning.org/2017/papers/7.pdf)

- **Bayesian Learning via Stochastic Gradient Langevin Dynamics** (2011) Welling & Teh [[pdf]](https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf)

#### **General Optimization:**

- **Convex Optimisation** (1992) Boyd & Vandenberghe [[pdf]](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)

- **Numerical Optimisation** (2006) Nocedal, Jorge, Wright, S [[pdf]](http://www.bioinfo.org.cn/~wangchao/maa/Numerical_Optimization.pdf)

#### **Reviews:**

- **An overview of gradient descent optimization algorithms** (2017) Sebastian Ruder [[pdf]](https://arxiv.org/abs/1609.04747)

---

#### **Course reading:**

[Princeton // Convex and Conic Optimization // ORF523](http://aaa.princeton.edu/orf523)

[Berkeley // Convex Optimisation and Approximation // EE 227C](https://ee227c.github.io/#material)


#### **Blogs etc:**

[SGD & CGD Convergence Notes](http://hduongtrong.github.io/2015/11/23/coordinate-descent/)

[Recht on Optimisation](https://simons.berkeley.edu/talks/ben-recht-2013-09-04)
